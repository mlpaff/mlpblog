---
title: Ovation Diagnostics
author: 'Matthew Paff'
date: '2018-02-02'
slug: ovation-diagnostics
coverImage: ../imgs/UT.jpg
thumbnailImagePosition: right
summary: "My Insight Health Data Science consulting project, identifying patients at risk for opioid dependence"
categories: ['Health Data Science']
tags: ['Opioid Epidemic', 'Genetics', 'Data Science']
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(cowplot) 
library(shiny)
library(knitr)
library(plotly)

ml_data = read.csv('../../../ml_data.csv')
df_raw <- read.csv('../../../admin_analytics_reports_011118.csv')
roc1 <- read.csv('../../../roc1.csv')
roc2 <- read.csv('../../../roc2.csv')
gene_pr <- read.csv('../../../pr_gene.csv')
clinic_pr <- read.csv('../../../pr_clinic.csv')
lr_feats1 <- read.csv('../../../lr_features.csv')
overlap <- read.csv("../../../opioid_overlap.csv")

#This spring I participated in the Insight Health Data Science Fellowship, working as a consultant for [Ovation](https://www.ovation.io/); a data management and solutions company that provides services for specialty diagnostic clinics. In addition to providing data management solutions, Ovation is working to provide data driven analytics and solutions to enhance patient care at the clinical level. Over the past few weeks, I have been collaborating with Barry Wark, CEO and Co-founder of Ovation, to see if we could leverage their clinic data to address a particularly important public health issue: the opioid epidemic.
```
# Identifying patients at risk for opioid dependence

*Matthew Paff, an Insight Health Data Science fellow (Spring, 2018), recently graduated from the University of Texas at Austin with a Ph.D. in Cell and Molecular Biology. There he modeled population dynamics of transmissible anti-viral defense using bacteriophage (viruses that infect bacteria) and developed novel approaches for genetically engineering attenuated vaccines.*

This spring I participated in the Insight Health Data Science fellowship program, working as a consultant for a company that provides data management solutions to specialty diagnostic clinics. Recently, they have been interested in expanding their role to include data-driven analytics to enhance the quality of patient care for their clients. Over the past few weeks, I have been working with this company to leverage their clinical data to address a particularly important public health issue: the opioid epidemic.

## Background

Opioid abuse is a serious public health crisis that has reached epidemic proportions over the past few years (figure 1). In 2016, there were over 42,249 [opioid-related deaths](https://www.cdc.gov/drugoverdose/data/statedeaths.html) in the United States. This is more than the number of Americans that die from breast cancer every year. It is currently the leading cause of injury death in the United States. Overprescription of pain medication is a significant contributor to this problem. In 2015, there were over 300 million opioid prescriptions written in the US, with [Americans consuming over 80%](https://www.cnbc.com/2016/04/27/americans-consume-almost-all-of-the-global-opioid-supply.html) of the global opioid supply. 

```{r heatMap, out.width = "100%", echo=FALSE, fig.cap="**Overdose deaths per 100,000 people (1999-2014)**. Haeyoun Park and Matthew Bloch - [The New York Times](https://nyti.ms/2jVUlKb)"}
include_graphics("https://static01.nyt.com/images/2017/10/26/us/drug-deaths-promo-guide/drug-deaths-promo-guide-superJumbo.jpg?quality=100&auto=webp")
```

Early identification of patients with opioid addiction or those who may be at increased risk of developing opioid abuse habits could be a crucial step in slowing this epidemic, at least when it comes to prescription pain medication. It is therefore important that we continue to develop novel approaches to identifying those that could be more susceptible to opioid addiction. Historically, physicians have relied primarily on subjective clinical risk factors such as family history, medical history, and various social and environmental factors, but there is increasing interest in utilizing [genetic screening](https://www.sciencedaily.com/releases/2017/12/171213130411.htm) to identify at-risk patients. 

The company that I consulted for was interested in asking whether they could take advantage of their clinical patient data to address this opioid dependence problem. More specifically, they wanted to measure the what contribution, if any, the clinic played in the identification of these patients. Here I used genetic sequencing data and information on the patients' clinics to train a machine-learning model in Python to identify patients diagnosed with opioid dependence. I was primarily interested in quantifying the role that the individual clinics play in making these predictions.

## The Data

I was provided with a dataset with information from over 3300 patients, a small random subset from their database. Within this data, I worked with three primary classes of information:

1. Patient diagnosis
2. Genetic sequencing results
3. Name of the clinic where each patient was treated

Included within these categories was information from over 1850 different diagnoses in the form of ICD-10 codes (International Statistical Classification of Diseases and Related Health Problems), 485 genes, and 121 clinics. Now this dataset was wonderfully complex and required quite a bit of initial manipulation and transformation. The first step however was rather straightforward. Since I was only interested in the opioid dependence diagnosis (at least initially), I selected only the ICD-10 codes related to opioid abuse, of which there were only 7, and combined them into a single binary column (positive or negative diagnosis), filtering out the remaining unassociated diseases.

In diving into the genetic data, I found that the distribution in sequencing converage was highly skewed (figure 1). Fewer than 40 genes were sequenced for more than 2000 patients. Coverage quickly drops off after that, with nearly 150 genes appearing to have been sequenced in fewer than 5 patients.

```{r genes, fig.cap="Distribution of gene sequencing coverage. Number of patients with sequencing information for a given gene", echo=FALSE, message=FALSE, fig.height=5}
# plot the distribution of gene sequencing coverage
gene_dist <- ml_data %>% mutate_if(is.factor, as.character) %>% gather(gene_locus, snp, 7:ncol(ml_data)) %>%
  filter(!snp %in% c('none')) %>% count(gene_locus) %>% arrange(desc(n)) %>%
  mutate(gene=row_number()) %>% 
  ggplot(aes(x=gene, y=n)) + 
  geom_bar(stat='identity', fill='#31a354') +
  scale_y_continuous(expand = c(0,0)) + 
  scale_x_continuous(expand=c(0,0)) + 
  labs(x = 'Gene', y = 'Number of patients') + 
  theme(axis.text = element_text(size = 14),
        axis.title = element_text(size = 18))
gene_dist_plot <- ggplotly(gene_dist, tooltip = c('x','y')) %>% layout(margin=list(l = 110, b=75))
ggplotly(gene_dist_plot, titleX=TRUE, titleY=TRUE)
# plot the coverage of sequencing for a given patient
# gene_coverage <- ml_data %>% mutate_if(is.factor, as.character) %>% gather(gene_locus, snp, 7:ncol(ml_data)) %>% 
#   filter(snp!='none') %>%
#   group_by(X) %>% count(X) %>% arrange(desc(n)) %>% ungroup() %>% mutate(num = row_number()) %>%
#   ggplot(aes(x=num, y=n)) +
#   geom_area(fill='#31a354') + 
#   scale_x_continuous(expand=c(0,0)) + 
#   scale_y_continuous(expand = c(0,0)) +
#   labs(x = 'Number of patients', y = 'Number genes sequenced') + 
#   theme(axis.text = element_text(size = 14),
#         axis.title = element_text(size = 18))
#gene_coverage_plot <- ggplotly(gene_coverage, tooltip = "none") %>% layout(margin=list(l = 110, b=75))

#subplot(gene_dist_plot, gene_coverage_plot, margin = 0.1, titleX = TRUE, titleY = TRUE)
```

In addition to uneven coverage, the genetic data was quite complex. Sequencing results for each of the 485 genes were in the form of SNP (single nucleotide polymorphisms) calls, or mutations. These SNPs were identified in several forms; the bases present in the assay (e.g. A/A/, A/G, T, -/C,...), whether a particular SNP was present, or as copy number variants (CNVs - e.g. 0, 1, 2,...). For a given gene, the patients could have one of anywhere between 0 and 8 unique SNP calls (those for which no test was performed were listed as 'none'). To transform this data into a form that could be used for model training, I used one-hot encoding, where each unique SNP call within a given gene becomes its own feature, now encoded as a binary value indicating whether the mutation is present or absent. One-hot encoding the genetic data resulted in an expansion in the dimentionality of me gene feature set (from 485 to more than 1300). In order to reduce some of this dimentionality, I chose to focus only on the features that contained actual genetic mutation information, removing the "none" gene features that only indicated lack of a test being performed. 

I next wanted to look at the distribution of patients with a positive opioid abuse diagnosis across the 121 clinics within the dataset. Out of the 121 clinics included, only 7 had at least 1 patient with a positive opioid abuse diagnosis. The ratio of positive to total patients within these 7 clincs varied significantly, from less than 1% to 87% (figure 1). In addition, the total number of positive opioid patients was only 175 compared to 3148 patients identified as negative for opioid abuse. This result indicated that the dataset was highly imbalanced; something that I would need to account for before implementing any sort of machine learning algorithm. 

```{r opProp, fig.cap = "Left - total number of negative (blue) and positive (orange) opioid abuse diagnoses. Right - Proportion of patients with a positive opioid abuse diagnosis for a given clinic compared to the total number of patients treated at that clinic. Only clinics with at least 1 opioid patient are included (114 remaining clinics have 0 patients with a positive diagnosis).", echo=FALSE, message=FALSE, fig.height=5, fig.align='center'}
ml_data$opioid_abuse <- factor(ml_data$opioid_abuse, levels=c(0,1))
clinic_labs <- c(
  'Louisville Behavioral Health Systems' = 'Clinic 1',
  'Luminus Diagnostics' = 'Clinic 2',
  'MAT of Georgia' = 'Clinic 3', 
  'Park Road Medical' = 'Clinic 4',
  'Pathway Outpatient Services, LLC' = 'Clinic 5',
  'Reliance Laboratory Testing' = 'Clinic 6',
  'Total Health Primary Care' = 'Clinic 7'
)

opioid_counts_plot <- ml_data %>% select(clinic, opioid_abuse) %>% 
  ggplot(aes(x=opioid_abuse, fill = opioid_abuse)) + 
  geom_bar(stat='count') +
  scale_x_discrete(labels = c('Negative', 'Positive')) + 
  scale_y_continuous(expand=c(0,0), limits = c(0, 3500)) + 
  scale_fill_manual(values = c('#56B4E9', '#D55E00')) +
  labs(x='Opioid abuse diagnosis', y= 'Number of patients') + 
  theme(legend.position = 'none',
    axis.title = element_text(size = 18),
    axis.text.y = element_text(size=14),
    axis.text.x = element_text(angle = 60, hjust = 1, size=14))

p1 <- ggplotly(opioid_counts_plot, tooltip = "y") %>% layout(margin = list(l = 110, b=150))

ratio <- ml_data %>% select(clinic, opioid_abuse) %>% group_by(clinic) %>% filter(n() > 10) %>%
  select(clinic, opioid_abuse) %>%
  count(opioid_abuse) %>% mutate(Ratio = round(n/sum(n), 4)) %>% filter(opioid_abuse==1) %>%
  ggplot(aes(y=Ratio, x=clinic)) +
  geom_bar(fill='#D55E00', stat='identity') +
  labs(y='% Positive opioid patients', x='Clinic') +
  scale_x_discrete(labels = clinic_labs) +
  scale_y_continuous(expand=c(0,0), limits = c(0,1)) +
  theme(legend.position = 'none',
    axis.title = element_text(size = 18),
    axis.text.y = element_text(size=14),
    axis.text.x = element_text(angle = 60, hjust = 1, size=14))

p2 <- ggplotly(ratio, tooltip = "y") %>% layout(margin=list(l = 110, b=150))

subplot(p1, p2, margin = 0.1, titleX = TRUE, titleY = TRUE)
```

## Model Implementation and Results

The primary goal of this project was to determine the role of the clinic in identifying those patients with increased risk of opioid dependence. My strategy for accomplishing this was to train two logistic regression models using scikit-learn in Python to predict the patients' opioid dependence diagnosis. The first model incorporated only the one-hot encoded genetic features (of which there were 876), while the second model incorporated both genetic information as well as the clinic where each patient received treatment. In training two separate models with and without the clinic data, I could compare their performances to determine the predictive contribution of the clinic information.

To train the models, I used 75% of the data, reserving the remaining 25% off for final validation of the models. The first thing I needed to do before training was balance the opioid abuse diagnosis classes. Training a logistic regression model without first balancing the diagnosis classes, would just result in a model that could just predict negative the entire time and still be highly accurate. I tested two methods of balancing, oversampling the under-represented class with replacement or changing the "class_weight" parameter to "balanced," which penalizes mis-classifying the minority class by an amount proportional to the level of imbalance. Both methods were comparable, but I used the "class_weight" balance to report my results here. 

Due to the high dimentionality as well as sparsity of some of my features, I used L1 regularization when performing the logistic regression. The benefit of L1 regularization is to reduce the coefficients of the unimportant features to 0, eliminating them as features in the model. Both models were implemented using the same training set, with the only difference being that I filtered out the clinic features before training the model to predict opioid abuse using the genotype data alone. 

The validation (test) set was used to calulate the receiver operator characteristic (ROC) and area under the curve (AUC) for both models (figure 4). The AUC improved signicantly, from 0.81 to 0.942, when including the clinic where the patients were treated in the model. 

```{r ROC, fig.cap = "Receiver operator characteristic plots from validation set for logistic regression models built from genotype (orange) alone and the combination of genotype and clinic (blue). AUC improves when clinic is included in the model", echo=FALSE, message=FALSE, fig.width=7}
# ROC plot
x1 <- data.frame(fpr = roc1$gene_lr_fpr, tpr = roc1$gene_lr_tpr) %>% mutate(label='roc1')
x2 <- data.frame(fpr = roc2$cg_fpr, tpr = roc2$cg_tpr) %>% mutate(label='roc2')
#x3 <- data.frame(fpr = roc3$fpr_m3, tpr = roc3$tpr_m3) %>% mutate(label='roc3')

test <- rbind(x1, x2)
test$label <- factor(test$label, levels = c('roc1', 'roc2'),
                     labels = c(
                       'roc1' = 'genotype (AUC = 0.81)',
                       'roc2' = 'genotype + clinic (AUC = 0.942)'))

roc_plot <- test %>% group_by(label) %>% mutate(FPR = round(fpr, 4), TPR = round(tpr, 4)) %>%
  ggplot(aes(x=FPR, y=TPR, color = label)) + 
  geom_line(size=1.4) + 
  scale_color_manual(values=c('#E69F00', "#56B4E9")) + 
  geom_abline(linetype=2) +
  scale_x_continuous(expand=c(0,0), limits=c(0,1.01)) + 
  scale_y_continuous(expand=c(0,0), limits=c(0,1.01)) + 
  labs(x="False positive rate", y = "True positive rate", color = 'Area under the curve') +
  theme(legend.position = c(0.35, 0.15), 
        legend.title = element_blank(),
        legend.key.size = unit(1, 'cm'),
        legend.text = element_text(size=14),
        axis.title = element_text(size=18))
roc_plot2 <- ggplotly(roc_plot, showlegend=TRUE, tooltip=c('x', 'y')) %>%
  layout(legend = list(x=0.45, y = 0.25, yanchor="top", margin=list(l = 110, b=150, t=40, r=100, pad=4)))

roc_plot2
```

While this measure indicates improved performance between the two models, the AUC is not always the ideal metric when the data is imbalanced since it is insensitive to the false positive rate. A second, potentially more informative metric this case might be the precision-recall curve, which is more informative to how well the models are classifying the patients (figure 5). Here the average precision score (AP) increases from 0.20 to 0.64, again illustrating superior performance when clinic is included in the model. 

```{r precision-recall, fig.cap="Precision-recall curves calulated from the validation set using the models for genotype (orange) alone and the combination of genotype and clinic (blue). Average precision score increases when clinic is included in the model", echo=FALSE, message=FALSE, fig.width=7}
g1 <- data.frame(pre = gene_pr$gene_precision, rec = gene_pr$gene_recall) %>% mutate(label='gene')
c1 <- data.frame(pre = clinic_pr$clinic_precision, rec = clinic_pr$clinic_recall) %>% mutate(label='clinic')

pr_df <- rbind(g1, c1)
pr_df$label <- factor(pr_df$label, levels = c('gene', 'clinic'),
                     labels = c(
                       'gene' = 'genotype (AP = 0.20)',
                       'clinic' = 'genotype + clinic (AP = 0.64)'))

precision_recall <- pr_df %>% group_by(label) %>%
  ggplot(aes(x=rec, y=pre, color = label)) + 
  geom_line(size=1.4) + 
  scale_color_manual(values=c('#E69F00', "#56B4E9")) + 
  #geom_abline(linetype=2) +
  scale_x_continuous(expand=c(0,0), limits=c(0,1.01)) + 
  scale_y_continuous(expand=c(0,0), limits=c(0,1.01)) + 
  labs(x="Recall", y = "Precision", color = 'AP') +
  theme(legend.position = c(0.45, 0.85), 
        legend.title = element_blank(),
        legend.key.size = unit(1, 'cm'),
        legend.text = element_text(size=14),
        axis.title = element_text(size=18))
precision_recall
#pre_rec_plot <- ggplotly(roc_plot, showlegend=TRUE, tooltip=c('x', 'y')) %>%
#  layout(legend = list(x=0.55, y = 0.25, yanchor="top", margin=list(l = 110, b=150, t=40, r=100, pad=4)))
```

```{r confusion, fig.cap="Confusion matrices for", echo=FALSE, message=FALSE, fig.height = 4}
# input data for builiding confusion matrix for clinic_genotype and genotype alone
FClassClinic <- factor(c(0, 0, 1, 1))
TClassClinic <- factor(c(0, 1, 0, 1))
Yclinic      <- c(5, 742, 39, 45)
clinic_mtx <- data.frame(FClassClinic, TClassClinic, Yclinic)

FClassGene <- factor(c(0, 0, 1, 1))
TClassGene <- factor(c(0, 1, 0, 1))
Ygene      <- c(13, 576, 31, 211)
gene_mtx <- data.frame(FClassGene, TClassGene, Ygene)

clinic_conf <- ggplot(data =  clinic_mtx, mapping = aes(x = FClassClinic, y = TClassClinic)) +
  geom_tile(aes(fill = Yclinic), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Yclinic)), size=8) +
  scale_x_discrete(expand=c(0,0), labels=c('Negative', 'Positive')) +
  scale_y_discrete(expand=c(0,0), labels = c('Positive', 'Negative')) +
  scale_fill_gradient(low = "#a5c3f6") +
  labs(x='Predicted label', y='True label', title='Genotype + clinic') +
  theme(legend.position = "none",
        axis.text.y = element_text(size=14, angle=90, hjust=.5),
        axis.text.x = element_text(size=14),
        axis.title = element_text(size=18),
        axis.line = element_blank())

gene_conf <- ggplot(data =  gene_mtx, mapping = aes(x = FClassGene, y = TClassGene)) +
  geom_tile(aes(fill = Ygene), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Ygene)), size=8) +
  scale_x_discrete(expand=c(0,0), labels=c('Negative', 'Positive')) +
  scale_y_discrete(expand=c(0,0), labels = c('Positive', 'Negative')) +
  scale_fill_gradient(low = "#fbd358", high='#ffaf36') +
  labs(x='Predicted label', y='True label', title='Genotype') +
  theme(legend.position = "none",
        axis.text.y = element_text(size=14, angle=90, hjust=.5),
        axis.text.x = element_text(size=14),
        axis.title = element_text(size=18),
        axis.line = element_blank())

#plot_grid(gene_conf, clinic_conf)
```

An additional benefit of using a logistic regression for this problem was that I could extract the important features (those with the highest absolute coefficient values) and evaluate whether they made sense with respect to being important predictors for a positive opioid diagnosis (figure 6). The top 4 most important features were all clinics, with the top two having the highest proportion of opioid patients in the dataset. As a form of validating these important clinics, I looked up the location for the top 3 clinics and found that they do in fact reside in areas with elevated opioid overdose rates. Interestingly, the following 4 important features were all genes that are part of the cytochrome P450 family of enzymes commonly found in drug metabolism pathways. Of note is the CYP2D6 gene, which commonly metabolizes opioids into morphine and variants have been identified as contributing to addiction-related pathways. 

```{r feat-importances, fig.cap="Important features from the model trained on the genotype and clinic data.", echo=FALSE, message=FALSE, fig.height=5}
lr_feats1$feature <- factor(lr_feats1$feature, levels = lr_feats1$feature[order(lr_feats1$importance, decreasing = F)])

feats1_labs <- c(
  'clinic_Pathway Outpatient Services, LLC' = 'Clinic 5',
  'clinic_Reliance Laboratory Testing' = 'Clinic 6',
  'clinic_MAT of Georgia' = 'Clinic 3',
  'clinic_Louisville Behavioral Health Systems' = 'Clinic 1',
  'C__30634242_40_C/C' = 'C__30634242_40',
  'CYP2D6_2' = 'CYP2D6',
  'C__60142977_10_T/T' = 'C__60142977_10',
  'C__26201809_30_C/C' = 'C__26201809_30',
  'hCV59013445_G/G'= 'hCV59013445',
  'C___1202883_20_G/A' = 'C___1202883_20',
  'C___8726802_20_G/G' = 'C___8726802_20',
  'C__25746809_50_G/G' = 'C__25746809_50',
  'clinic_Prism Health Dx' = 'Clinic 8'
)

lr_feats1 %>% 
  ggplot(aes(x=feature, y=importance, fill = feature)) +
  geom_bar(stat='identity', fill = '#56B4E9') + 
  coord_flip() +
  scale_x_discrete(labels = feats1_labs) +
  #scale_fill_manual(values = c('#56B4E9', '#56B4E9', '#56B4E9','#56B4E9','#56B4E9','#56B4E9',
  #                             '#56B4E9','#56B4E9','#56B4E9','#56B4E9', 'black', 'green', 'purple')) + 
  labs(y='Feature Importance') +
  theme(legend.position= 'none', 
        axis.title.y = element_blank(),
        axis.title.x = element_text(size=20),
        axis.text = element_text(size=14)) -> feat_importances
feat_importances
```

## Conclusions

These modeling efforts reveal a potentially powerful tool that could aid in identifying patients at risk for developing opioid dependence. These results suggest that in addition to genotype data, the clinic plays an important role in identifying patients with opioid dependence. It is important to recognize that genotype alone cannot and should not be used diagnose opioid dependence on its own, but could rather be used as an indicator for increased likelihood of susceptibility to dependance. While the efforts discussed here are preliminary and limited to a small sample size, it points towards a potentially useful application in identifying such patients so that future treatment can attempt to minimize their risk of converting to a dependent state. 

In performing my analysis, I was also interested in looking at the overlapping diagnoses that accompanied the positive opioid abuse diagnosis. I found that there were 12 diagnoses within this dataset that correlated with opioid abuse (figure 7). In the future, these features could be incorporated into the model to improve how we identify the at-risk patients. 

```{r overlapping-diseases, fig.cap="Patient counts for diseases that occurred concurrently with the opioid dependence diagnosis", echo=FALSE, message=FALSE, fig.height=5}
t1 <- overlap %>% filter(multi_diags==2)

disease_labs <- c(
  'F10.10' = 'Alcohol abuse',
  'F10.20' = 'Alcohol dependence',
  'F12.20' = 'Cannabis dependence',
  'F32.2' = 'Depression',
  'F33.1' = 'Recurrent depression',
  'F33.2' = 'Psychotic depression',
  'F33.9' = 'Unspecified depression',
  'F41.1' = 'General anxiety',
  'F41.9' = 'Unspecified anxiety',
  'G47.00' = 'Insomnia',
  'unnamed..9' = 'unidentified',
  'Z79.899' = 'Long-term drug therapy'
)

Filter(function(u) any(grepl('1',u)), overlap) %>% select(-opioid_abuse) %>% gather(disease, diag, I10:F43.21) %>%
  group_by(disease) %>% filter(diag==1) %>% count() %>% filter(n>4) %>% 
  ggplot(aes(x=disease, y=n)) + 
  geom_bar(stat='identity', fill = '#56B4E9') + 
  scale_y_continuous(expand=c(0,0)) + 
  scale_x_discrete(labels=disease_labs) +
  labs(y = 'Number of patients') +
  coord_flip() +
  theme(axis.title.y = element_blank(),
        axis.title.x = element_text(size=20),
        axis.text.x = element_text(size=12)) -> overlap_plot
overlap_plot
```

An ideal model, and one that was outside of the scope of what I could accomplish within this project, might be one that identifies populations or even geographic regions with elevated opioid dependence risk so that genetic screening could be used to quantify individual patient-risk for opioid abuse. The idea being that one could suggest that clinics found in these "hot-spot" regions perform these genetic tests so that pain medication prescriptions and dosages could be personalized to reduce the likelihood of converting a patient to a dependent state while still providing adequate pain management. Incorporating data on demographics, geographic location, and potential indicator diagnoses (e.g. long-term drug therapy) would be useful in implementing such a model.

Demo slides can be found [here](https://docs.google.com/presentation/d/1eIifHITMQxFXhcWFmiNOls03I0ydZka_jO2FMpb7H6o/edit?usp=sharing)
